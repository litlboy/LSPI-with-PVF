{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSPI with PDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lspi import LSPI\n",
    "from basis import *\n",
    "from utils import *\n",
    "import gym\n",
    "import pickle\n",
    "#from grid import make_grid\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib import cm\n",
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_off_lspi(env, tol, horizon, n_episodes, basis_name, covering, cutsom=None, **kwargs):\n",
    "    \n",
    "    # Sampling parameters\n",
    "    horizon = horizon\n",
    "    n_episodes = n_episodes\n",
    "\n",
    "    # Raw sampling\n",
    "    data = collect_episodes(env, horizon=horizon, n_episodes=n_episodes, custom=custom)\n",
    "    print('%s states encountered during the random walk' %len(data))\n",
    "    \n",
    "    nactions = env.action_space.n\n",
    "    \n",
    "    if basis_name == 'RBF':\n",
    "        means = kwargs['means']\n",
    "        gamma = kwargs['gamma']\n",
    "        basis = RadialBasisFunction(means, gamma, nactions)\n",
    "    \n",
    "    if basis_name == 'PVF':\n",
    "        \n",
    "        # Subsample to build pvfs\n",
    "        graph_states = subsample([data[i][0] for i in range(len(data))], covering)\n",
    "        print('%s states were kept to build the laplacian'%len(graph_states))\n",
    "        \n",
    "        num_eig = kwargs['num_eigens']\n",
    "        var = kwargs['variance']\n",
    "        nn = kwargs['num_neighbors']\n",
    "        print('Computing the Laplacian')\n",
    "        # Learn state manifold\n",
    "        basis = ProtoValueBasis(graph_states, var, nn, nactions)\n",
    "        print('Laplacian computed')\n",
    "        basis.set_num_features(num_eig)\n",
    "    \n",
    "    print('Start training')\n",
    "    lspi = LSPI(data, basis, GAMMA, nactions)\n",
    "    theta = np.random.rand(basis.size())\n",
    "    i = 0\n",
    "    dist = np.inf\n",
    "    while dist > tol:\n",
    "        old_theta = copy.copy(theta)\n",
    "        theta = lspi.iteration(theta)\n",
    "        i += 1\n",
    "        dist = np.linalg.norm(old_theta - theta)\n",
    "    print('Training complete')\n",
    "    \n",
    "    # Evaluate policy\n",
    "    l = []\n",
    "    for _ in range(30): \n",
    "        s = env.reset()\n",
    "        term = False\n",
    "        length = 0\n",
    "        while not term and length < 500:\n",
    "            q = np.dot(basis.evaluate(s), theta)\n",
    "            action = np.argmax(q)\n",
    "            s, _, term, _ = env.step(action)\n",
    "            length += 1\n",
    "        l.append(length)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tolerance for lspi\n",
    "tol = 0.05\n",
    "\n",
    "# Global number of features\n",
    "num_features = 25\n",
    "\n",
    "# PVF parameters\n",
    "var = 0.25\n",
    "nn = 20\n",
    "\n",
    "# Args\n",
    "kwargs = {'num_eigens':num_features, \n",
    "          'num_neighbors':nn, 'variance':var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "espilon_covering = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Acrobot-v1')\n",
    "espilon_covering['acrobot'] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "env._max_episode_steps = np.inf\n",
    "horizon = 100000\n",
    "n_episodes = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63417 states encountered during the random walk\n",
      "Computing the Laplacian\n",
      "Laplacian computed\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 138.2879858224527\n",
      "2 iterations completed\n",
      "Current distance 35.48782232617139\n",
      "3 iterations completed\n",
      "Current distance 0.11638567631398805\n",
      "4 iterations completed\n",
      "Current distance 5.5104580033949405e-05\n",
      "74669 states encountered during the random walk\n",
      "Computing the Laplacian\n",
      "Laplacian computed\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 162.01363150220885\n",
      "2 iterations completed\n",
      "Current distance 42.887822281224935\n",
      "3 iterations completed\n",
      "Current distance 0.5071892069883043\n",
      "4 iterations completed\n",
      "Current distance 0.000245035023191832\n",
      "71573 states encountered during the random walk\n",
      "Computing the Laplacian\n",
      "Laplacian computed\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 177.12106399120594\n",
      "2 iterations completed\n",
      "Current distance 45.3814379202748\n",
      "3 iterations completed\n",
      "Current distance 0.4605846389122085\n",
      "4 iterations completed\n",
      "Current distance 0.000328100091959405\n",
      "75350 states encountered during the random walk\n",
      "Computing the Laplacian\n",
      "Laplacian computed\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 152.08911003811\n",
      "2 iterations completed\n",
      "Current distance 40.45012065033638\n",
      "3 iterations completed\n",
      "Current distance 0.12702946224208905\n",
      "4 iterations completed\n",
      "Current distance 6.970297683274444e-05\n",
      "87974 states encountered during the random walk\n",
      "Computing the Laplacian\n",
      "Laplacian computed\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 162.14393231182066\n",
      "2 iterations completed\n",
      "Current distance 44.16782003894321\n",
      "3 iterations completed\n",
      "Current distance 0.21792182924791073\n",
      "4 iterations completed\n",
      "Current distance 0.00031940477691508247\n"
     ]
    }
   ],
   "source": [
    "res_pvf_acrobot = []\n",
    "for _ in range(5):\n",
    "    res_pvf_acrobot.append(run_off_lspi(env, tol, horizon, \n",
    "                                        n_episodes, 'PVF', covering=epsilon_covring['acrobot'], **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77864 states encountered during the random walk\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 37.41086352747375\n",
      "2 iterations completed\n",
      "Current distance 0.9826635640391354\n",
      "3 iterations completed\n",
      "Current distance 0.02053861204002026\n",
      "69526 states encountered during the random walk\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 37.41541669316846\n",
      "2 iterations completed\n",
      "Current distance 0.6918741733686892\n",
      "3 iterations completed\n",
      "Current distance 0.00855038658772186\n",
      "84680 states encountered during the random walk\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 37.39211235386282\n",
      "2 iterations completed\n",
      "Current distance 0.3523143814492172\n",
      "3 iterations completed\n",
      "Current distance 0.002179173168508964\n",
      "82660 states encountered during the random walk\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 37.40779669059466\n",
      "2 iterations completed\n",
      "Current distance 0.7386349896739763\n",
      "3 iterations completed\n",
      "Current distance 0.03971080428592329\n",
      "65590 states encountered during the random walk\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 37.410184530518144\n",
      "2 iterations completed\n",
      "Current distance 0.4381026952033203\n",
      "3 iterations completed\n",
      "Current distance 0.025227797739506827\n"
     ]
    }
   ],
   "source": [
    "res_rbf_acrobot = []\n",
    "for _ in range(5):\n",
    "    res_rbf_acrobot.append(run_off_lspi(env, tol, horizon,\n",
    "                                        n_episodes, 'RBF', covering=epsilon_covring['acrobot'],**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(res_pvf_acrobot, open('res_pvf_acrobot', 'wb'))\n",
    "pickle.dump(res_rbf_acrobot, open('res_rbf_acrobot', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/litlboy/anaconda3/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "espilon_covering['cartpole'] = 0.08\n",
    "\n",
    "# Sampling parameters\n",
    "horizon = 70\n",
    "n_episodes = 700\n",
    "\n",
    "# Custom reward (none provided by gym)\n",
    "custom = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15841 states encountered during the random walk\n",
      "Computing the Laplacian\n",
      "Laplacian computed\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 18021.698933237294\n",
      "2 iterations completed\n",
      "Current distance 15887.886142270498\n",
      "3 iterations completed\n",
      "Current distance 9679.367617612148\n",
      "4 iterations completed\n",
      "Current distance 8442.82583816962\n",
      "5 iterations completed\n",
      "Current distance 7856.926240115174\n",
      "6 iterations completed\n",
      "Current distance 12368.622615572887\n",
      "7 iterations completed\n",
      "Current distance 3946.5799666590074\n",
      "8 iterations completed\n",
      "Current distance 8562.895392718705\n",
      "9 iterations completed\n",
      "Current distance 7288.76729552844\n",
      "10 iterations completed\n",
      "Current distance 5252.955791016443\n",
      "11 iterations completed\n",
      "Current distance 411.220024994828\n",
      "12 iterations completed\n",
      "Current distance 63.674838320183035\n",
      "13 iterations completed\n",
      "Current distance 0.4142883118903049\n",
      "14 iterations completed\n",
      "Current distance 0.0\n",
      "15409 states encountered during the random walk\n",
      "Computing the Laplacian\n",
      "Laplacian computed\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 8572.150003017987\n",
      "2 iterations completed\n",
      "Current distance 11388.51128679941\n",
      "3 iterations completed\n",
      "Current distance 7303.845124312536\n",
      "4 iterations completed\n",
      "Current distance 27682.733076583954\n",
      "5 iterations completed\n",
      "Current distance 53408.64183474935\n",
      "6 iterations completed\n",
      "Current distance 45457.258181372505\n",
      "7 iterations completed\n",
      "Current distance 8813.62235461892\n",
      "8 iterations completed\n",
      "Current distance 7768.91254877719\n",
      "9 iterations completed\n",
      "Current distance 491.9306395736278\n",
      "10 iterations completed\n",
      "Current distance 1425.0473122200365\n",
      "11 iterations completed\n",
      "Current distance 77.25117687866832\n",
      "12 iterations completed\n",
      "Current distance 0.8156412300065244\n",
      "13 iterations completed\n",
      "Current distance 0.0\n",
      "15555 states encountered during the random walk\n",
      "Computing the Laplacian\n",
      "Laplacian computed\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 8808.624630506203\n",
      "2 iterations completed\n",
      "Current distance 11149.059074991123\n",
      "3 iterations completed\n",
      "Current distance 397647.6784322176\n",
      "4 iterations completed\n",
      "Current distance 398833.44541072135\n",
      "5 iterations completed\n",
      "Current distance 12375.245112932387\n",
      "6 iterations completed\n",
      "Current distance 6102.979602829108\n",
      "7 iterations completed\n",
      "Current distance 8179.0522308093605\n",
      "8 iterations completed\n",
      "Current distance 6952.150266476648\n",
      "9 iterations completed\n",
      "Current distance 3791.5717612211038\n",
      "10 iterations completed\n",
      "Current distance 7456.426623773213\n",
      "11 iterations completed\n",
      "Current distance 1664.5365114701015\n",
      "12 iterations completed\n",
      "Current distance 578.023842258701\n",
      "13 iterations completed\n",
      "Current distance 56.61788843757022\n",
      "14 iterations completed\n",
      "Current distance 0.13159375291701225\n",
      "15 iterations completed\n",
      "Current distance 0.0\n",
      "15647 states encountered during the random walk\n",
      "Computing the Laplacian\n",
      "Laplacian computed\n",
      "Start training\n",
      "1 iterations completed\n",
      "Current distance 12831.97313209817\n",
      "2 iterations completed\n",
      "Current distance 8734.048179627112\n",
      "3 iterations completed\n",
      "Current distance 16178.984321944015\n",
      "4 iterations completed\n",
      "Current distance 14388.644089445148\n",
      "5 iterations completed\n",
      "Current distance 5310.360632121607\n",
      "6 iterations completed\n",
      "Current distance 4994.737661136096\n",
      "7 iterations completed\n",
      "Current distance 8504.976836542028\n",
      "8 iterations completed\n",
      "Current distance 12572.546119519013\n",
      "9 iterations completed\n",
      "Current distance 9964.736400782967\n",
      "10 iterations completed\n",
      "Current distance 1793.0414830662544\n",
      "11 iterations completed\n",
      "Current distance 2509.196384230793\n",
      "12 iterations completed\n",
      "Current distance 263.7915180747036\n",
      "13 iterations completed\n",
      "Current distance 6.098338088806589\n",
      "14 iterations completed\n",
      "Current distance 0.03060139918013883\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    res_pvf_cartpole.append(run_off_lspi(env, tol, \n",
    "                    horizon, n_episodes, 'PVF', custom=custom, covering=espilon_covering['cartpole'], **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(res_pvf_cartpole,open('res_pvf_cartpole', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF parameters\n",
    "means = build_rbf_centers(env, num_features)\n",
    "gamma = 1\n",
    "\n",
    "kwargs['means'] = means\n",
    "kwargs['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15559 states encountered during the random walk\n",
      "Start training\n",
      "Training complete\n",
      "15087 states encountered during the random walk\n",
      "Start training\n",
      "Training complete\n",
      "15481 states encountered during the random walk\n",
      "Start training\n",
      "Training complete\n",
      "15274 states encountered during the random walk\n",
      "Start training\n",
      "Training complete\n",
      "15636 states encountered during the random walk\n",
      "Start training\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "res_rbf_cartpole = []\n",
    "for _ in range(5):\n",
    "    res_rbf_cartpole.append(run_off_lspi(env, tol, \n",
    "                    horizon, n_episodes, 'RBF', custom=custom, covering=None, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(res_rbf_cartpole, open('Results/res_rbf_cartpole', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Mountain car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/litlboy/anaconda3/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env._max_episode_steps = np.inf\n",
    "env._max_episode_seconds = np.inf\n",
    "\n",
    "# For subsampling\n",
    "espilon_covering['mc'] = 0.01\n",
    "\n",
    "# Sampling parameters\n",
    "horizon = 10000\n",
    "n_episodes = 3\n",
    "\n",
    "# Custom reward (none provided by gym)\n",
    "custom = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_off_lspi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c45dfa1d87c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres_pvf_mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     res_pvf_mc.append(run_off_lspi(env, tol, \n\u001b[0m\u001b[1;32m      4\u001b[0m                     horizon, n_episodes, 'PVF', custom=custom, covering=espilon_covering['mc'], **kwargs))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_off_lspi' is not defined"
     ]
    }
   ],
   "source": [
    "res_pvf_mc = []\n",
    "for _ in range(5):\n",
    "    res_pvf_mc.append(run_off_lspi(env, tol, \n",
    "                    horizon, n_episodes, 'PVF', custom=custom, covering=espilon_covering['mc'], **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rbf_mc = []\n",
    "for _ in range(5):\n",
    "    res_pvf_mc.append(run_off_lspi(env, tol, \n",
    "                    horizon, n_episodes, 'RBF', custom=custom, covering=None, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pvf_cartpole = np.array(pickle.load(open('Results/res_pvf_cartpole', 'rb')))\n",
    "res_pvf_acrobot = np.array(pickle.load(open('Results/res_pvf_acrobot', 'rb')))\n",
    "res_rbf_cartpole = np.array(pickle.load(open('Results/res_rbf_cartpole', 'rb')))\n",
    "res_rbf_acrobot = np.array(pickle.load(open('Results/res_rbf_acrobot', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_pvf_c = np.mean(res_pvf_cartpole, axis=1)\n",
    "means_pvf_a = np.mean(res_pvf_acrobot, axis=1)\n",
    "means_rbf_c = np.mean(res_rbf_cartpole, axis=1)\n",
    "means_rbf_a = np.mean(res_rbf_acrobot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PVF CartPole, mean perf = 160.85999999999999 std = 54.005910787616564\n",
      "RBF CartPole, mean perf = 95.80666666666667 std = 9.736698048562914\n",
      "\n",
      "PVF Acrobot, mean perf = 176.51333333333332 std = 82.30775203129072\n",
      "RBF Acrobot, mean perf = 473.88 std = 41.31294443364909\n"
     ]
    }
   ],
   "source": [
    "print('PVF CartPole, mean perf = ' + str(np.mean(means_pvf_c)) + ' std = ' + str(np.var(means_pvf_c)**0.5))\n",
    "print('RBF CartPole, mean perf = ' + str(np.mean(means_rbf_c)) + ' std = ' + str(np.var(means_rbf_c)**0.5))\n",
    "print('')\n",
    "print('PVF Acrobot, mean perf = ' + str(np.mean(means_pvf_a)) + ' std = ' + str(np.var(means_pvf_a)**0.5))\n",
    "print('RBF Acrobot, mean perf = ' + str(np.mean(means_rbf_a)) + ' std = ' + str(np.var(means_rbf_a)**0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
